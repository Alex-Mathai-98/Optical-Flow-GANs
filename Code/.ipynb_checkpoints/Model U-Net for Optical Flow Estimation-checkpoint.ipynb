{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alex/Desktop/Fall_Dataset_GANs/nonfall\n",
      "['Fashion MNIST.ipynb', 'adl-25.npy', 'adl-13.npy', 'adl-09.npy', 'adl-05.npy', 'adl-33.npy', 'adl_dataset_create.ipynb', 'adl-23.npy', 'adl-07.npy', 'adl-11.npy', 'adl_dataset.hdf5', '1. Intro to PyTorch.ipynb', 'adl-37.npy', 'adl-34.npy', 'adl_indices.pkl', 'adl-27.npy', 'Preprocess.ipynb', 'Linear Regression in Pytorch.ipynb', 'adl-28.npy', 'adl-10.npy', 'GradientDescent.ipynb', '2. Starting with NNs in PyTorch (MNIST).ipynb', 'FFN.ipynb', 'adl-21.npy', 'adl-01.npy', 'adl-16.npy', 'adl-22.npy', 'PyTorch workshop', 'adl-35.npy', 'adl-06.npy', 'adl-38.npy', 'adl-03.npy', '.ipynb_checkpoints', 'adl-24.npy', 'Inference and Validation.ipynb', 'adl-39.npy', 'Model U-Net for Optical Flow Estimation.ipynb', 'adl-29.npy', 'adl-12.npy', 'adl-40.npy', 'adl-32.npy', 'adl-14.npy', 'adl-18.npy', 'adl-17.npy', 'adl-02.npy', 'adl-20.npy', 'adl-15.npy', 'adl-30.npy', 'adl-26.npy', 'adl-08.npy', '3. Training our Neural Network.ipynb', 'adl-04.npy', 'adl-31.npy', 'adl-19.npy', 'adl-36.npy']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import pickle\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "print(os.getcwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdlDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, hdf5_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        f = h5py.File(hdf5_file, 'r')\n",
    "\n",
    "        self.dset = f['default']\n",
    "        self.transform = transform\n",
    "        \n",
    "        with open(\"adl_indices.pkl\",\"rb\") as f:\n",
    "            self.indices = pickle.load(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx2 = self.indices[idx]\n",
    "        sample = self.dset[idx2:idx2+10]\n",
    "        sample = sample.transpose([1,2,3,0])\n",
    "        sample = sample.reshape([240,320,-1])\n",
    "        sample = sample[:,40:280,:]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "adl_dset = AdlDataset(\"adl_dataset.hdf5\",transform)\n",
    "dataloader = DataLoader(adl_dset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 240, 240])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = next( iter(dataloader) ) \n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_input = np.load('./adl-27.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 240, 320, 2)\n"
     ]
    }
   ],
   "source": [
    "print(demo_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Layer 1 - Left\n",
    "        self.conv1 = nn.Conv2d(18, 18,kernel_size=(2,2),stride=(2,2),padding=(8,8)) #size (20,128,128)\n",
    "        self.PReLU1 = nn.PReLU()\n",
    "        self.bn1 = torch.nn.BatchNorm2d(num_features=18)\n",
    "        self.conv2 = nn.Conv2d(18, 32,kernel_size=(3,3),stride=(1,1),padding=1) #size (32,128,128)\n",
    "        self.PReLU2 = nn.PReLU()\n",
    "        self.bn2 = torch.nn.BatchNorm2d(num_features=32)\n",
    "        \n",
    "        # Layer 2 - Left\n",
    "        self.conv3 = nn.Conv2d(32, 32,kernel_size=(3,3),stride=(1,1),padding=0,dilation=4) #size (32,120,120)\n",
    "        self.PReLU3 = nn.PReLU()\n",
    "        self.bn3 = torch.nn.BatchNorm2d(num_features=32)\n",
    "        self.conv4 = nn.Conv2d(32, 64,kernel_size=(3,3),stride=(1,1),padding=1) #size (64,120,120)\n",
    "        self.PReLU4 = nn.PReLU()\n",
    "        self.bn4 = torch.nn.BatchNorm2d(num_features=64)\n",
    "        \n",
    "        # Layer 3 - Left\n",
    "        self.conv5 = nn.Conv2d(64, 64,kernel_size=(3,3),stride=(1,1),padding=0,dilation=8) #size (64,104,104)\n",
    "        self.PReLU5 = nn.PReLU()\n",
    "        self.bn5 = torch.nn.BatchNorm2d(num_features=64)\n",
    "        self.conv6 = nn.Conv2d(64, 128,kernel_size=(3,3),stride=(1,1),padding=1)#size (128,104,104)\n",
    "        self.PReLU6 = nn.PReLU()\n",
    "        self.bn6 = torch.nn.BatchNorm2d(num_features=128)\n",
    "        \n",
    "        # Layer 4 - Middle\n",
    "        self.conv7_part1 = nn.Conv2d(128,128,kernel_size=(3,3),stride=(1,1),padding=0,dilation=16) #size (128,72,72) \n",
    "        self.PReLU7_part1 = nn.PReLU()\n",
    "        self.bn7_part1 = torch.nn.BatchNorm2d(num_features=128)\n",
    "        \n",
    "        self.conv7_part2 = nn.Conv2d(128,128,kernel_size=(3,3),stride=(1,1),padding=1) #size (128,72,72) \n",
    "        self.PReLU7_part2 = nn.PReLU()\n",
    "        self.bn7_part2 = torch.nn.BatchNorm2d(num_features=128)\n",
    "        \n",
    "        self.deconv8 = nn.ConvTranspose2d(128,128,kernel_size=(3,3),stride=(1,1),padding=0,dilation=16) #size (64,104,104)\n",
    "        \n",
    "        # Layer 5 - Right\n",
    "        self.conv9 = nn.Conv2d(128+128,64,kernel_size=(3,3),stride=(1,1),padding=1) #size (64,104,104)\n",
    "        self.PReLU9 = nn.PReLU()\n",
    "        self.bn9 = torch.nn.BatchNorm2d(num_features=64)\n",
    "        self.conv10 = nn.Conv2d(64,64, kernel_size=(3,3),stride=(1,1),padding=1)#size (64,104,104)                          \n",
    "        self.PReLU10 = nn.PReLU()\n",
    "        self.bn10 = torch.nn.BatchNorm2d(num_features=64)\n",
    "        \n",
    "        self.deconv11 = nn.ConvTranspose2d(64,64,kernel_size=(3,3),stride=(1,1),padding=0,dilation=8) #size (64,120,120)\n",
    "        \n",
    "        # Layer 6 - Right\n",
    "        self.conv12 = nn.Conv2d(64+64,32,kernel_size=(3,3),stride=(1,1),padding=1) #size (32,120,120)\n",
    "        self.PReLU12 = nn.PReLU()\n",
    "        self.bn12 = torch.nn.BatchNorm2d(num_features=32)\n",
    "        self.conv13 = nn.Conv2d(32,32,kernel_size=(3,3),stride=(1,1),padding=1) #size (32,120,120)\n",
    "        self.PReLU13 = nn.PReLU()\n",
    "        self.bn13 = torch.nn.BatchNorm2d(num_features=32)\n",
    "        \n",
    "        self.deconv14 = nn.ConvTranspose2d(32,32,kernel_size=(3,3),stride=(1,1),padding=0,dilation=4) #size (32,128,128)\n",
    "        \n",
    "        # Layer 7 - Right\n",
    "        self.conv15 = nn.Conv2d(32+32,20,kernel_size=(3,3),stride=(1,1),padding=1) #size (20,128,128)\n",
    "        self.PReLU15 = nn.PReLU()\n",
    "        self.bn15 = torch.nn.BatchNorm2d(num_features=20)\n",
    "        self.conv16 = nn.Conv2d(20,20,kernel_size=(3,3),stride=(1,1),padding=1) #size (20,128,128)\n",
    "        self.PReLU16 = nn.PReLU()\n",
    "        self.bn16 = torch.nn.BatchNorm2d(num_features=20)\n",
    "        \n",
    "        self.deconv17 = nn.ConvTranspose2d(20,20,kernel_size=(2,2),stride=(2,2),padding=(8,8),dilation=1) #size (20,240,240)\n",
    "        \n",
    "        # Layer 8 - Right\n",
    "        self.conv18 = nn.Conv2d(20,20,kernel_size=(3,3),stride=(1,1),padding=1) #size (20,240,240)\n",
    "        self.PReLU18 = nn.PReLU()\n",
    "        self.bn18 = torch.nn.BatchNorm2d(num_features=20)\n",
    "        self.conv19 = nn.Conv2d(20,2,kernel_size=(3,3),stride=(1,1),padding=1) #size (2,240,240)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.bn1(self.PReLU1(self.conv1(x)))\n",
    "        x2 = self.bn2(self.PReLU2(self.conv2(x1)))\n",
    "        x3 = self.bn3(self.PReLU3(self.conv3(x2)))\n",
    "        x4 = self.bn4(self.PReLU4(self.conv4(x3)))\n",
    "        x5 = self.bn5(self.PReLU5(self.conv5(x4)))\n",
    "        x6 = self.bn6(self.PReLU6(self.conv6(x5)))\n",
    "        x7 = self.bn7_part1(self.PReLU7_part1(self.conv7_part1(x6)))\n",
    "        x7 = self.bn7_part2(self.PReLU7_part2(self.conv7_part2(x7)))\n",
    "        \n",
    "        x8 = self.deconv8(x7)\n",
    "        \n",
    "        print(\"X6 Shape {}\".format(x6.shape))\n",
    "        print(\"X8 Shape {}\".format(x8.shape))\n",
    "        input_9 = torch.cat((x8,x6),dim=1)\n",
    "        assert( input_9.shape[1:] == (256,104,104) )\n",
    "        x9 = self.bn9(self.PReLU9(self.conv9(input_9)))\n",
    "        x10 = self.bn10(self.PReLU10(self.conv10(x9)))\n",
    "        \n",
    "        x11 = self.deconv11(x10)\n",
    "        \n",
    "        print(\"X11 Shape {}\".format(x11.shape))\n",
    "        print(\"X4 Shape {}\".format(x4.shape))\n",
    "        input_12 = torch.cat((x11,x4), dim=1)\n",
    "        assert( input_12.shape[1:] == (128,120,120) )\n",
    "        x12 = self.bn12(self.PReLU12(self.conv12(input_12)))\n",
    "        x13 = self.bn13(self.PReLU13(self.conv13(x12)))\n",
    "        \n",
    "        x14 = self.deconv14(x13)\n",
    "        \n",
    "        print(\"X14 Shape {}\".format(x14.shape))\n",
    "        print(\"X2 Shape {}\".format(x2.shape))\n",
    "        input_15 = torch.cat((x14,x2), dim=1)\n",
    "        assert( input_15.shape[1:] == (64,128,128) )\n",
    "        x15 = self.bn15(self.PReLU15(self.conv15(input_15)))\n",
    "        x16 = self.bn16(self.PReLU16(self.conv16(x15)))\n",
    "        \n",
    "        x17 = self.deconv17(x16)\n",
    "        \n",
    "        x18 = self.bn18(self.PReLU18(self.conv18(x17)))\n",
    "        x19 = self.conv19(x18)\n",
    "        \n",
    "        return x19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(20, 16,kernel_size=(2,2),stride=(2,2),padding=(8,8)) #size (16,128,128)\n",
    "        self.PReLU1 = nn.PReLU()\n",
    "        self.bn1 = torch.nn.BatchNorm2d(num_features=16)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 8,kernel_size=(2,2),stride=(2,2)) #size (8,64,64)\n",
    "        self.PReLU2 = nn.PReLU()\n",
    "        self.bn2 = torch.nn.BatchNorm2d(num_features=8)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(8, 4,kernel_size=(2,2),stride=(2,2))  #size (4,32,32)\n",
    "        self.PReLU3 = nn.PReLU()\n",
    "        self.bn3 = torch.nn.BatchNorm2d(num_features=4)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(4,2, kernel_size=(2,2),stride=(2,2)) #size (2,16,16)\n",
    "        self.PReLU4 = nn.PReLU()\n",
    "        self.bn4 = torch.nn.BatchNorm2d(num_features=2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(2,1, kernel_size=(2,2),stride=(2,2)) #size (1,8,8)\n",
    "        self.PReLU5 = nn.PReLU()\n",
    "        self.bn5 = torch.nn.BatchNorm2d(num_features=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64,32)\n",
    "        self.PReLU_fc1 = nn.PReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(32,16)\n",
    "        self.PReLU_fc2 = nn.PReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(16,8)\n",
    "        self.PReLU_fc3 = nn.PReLU()\n",
    "        \n",
    "        self.fc4 = nn.Linear(8,1)\n",
    "        self.sig_fc4 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convs\n",
    "        x1 = self.bn1(self.PReLU1(self.conv1(x)))\n",
    "        x2 = self.bn2(self.PReLU2(self.conv2(x1)))\n",
    "        x3 = self.bn3(self.PReLU3(self.conv3(x2)))\n",
    "        x4 = self.bn4(self.PReLU4(self.conv4(x3)))\n",
    "        x5 = self.bn5(self.PReLU5(self.conv5(x4)))\n",
    "        \n",
    "        # Flatten\n",
    "        x5 = x5.view(x.shape[0], -1)\n",
    "        print(x5.shape)\n",
    "        \n",
    "        # Fully Connected\n",
    "        x6 = self.PReLU_fc1(self.fc1(x5))\n",
    "        x7 = self.PReLU_fc2(self.fc2(x6))\n",
    "        x8 = self.PReLU_fc3(self.fc3(x7))\n",
    "        x9 = self.sig_fc4(self.fc4(x8))\n",
    "        \n",
    "        return x9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(model):\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for param in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(param.size()):\n",
    "            nn = nn*s\n",
    "        count += nn\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887047\n",
      "4798\n"
     ]
    }
   ],
   "source": [
    "gen = Generator()\n",
    "print( get_params(alex) )\n",
    "\n",
    "disc = Discriminator()\n",
    "print( get_params(alex2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X6 Shape torch.Size([10, 128, 104, 104])\n",
      "X8 Shape torch.Size([10, 128, 104, 104])\n",
      "X11 Shape torch.Size([10, 64, 120, 120])\n",
      "X4 Shape torch.Size([10, 64, 120, 120])\n",
      "X14 Shape torch.Size([10, 32, 128, 128])\n",
      "X2 Shape torch.Size([10, 32, 128, 128])\n",
      "torch.Size([10, 2, 240, 240])\n",
      "torch.Size([10, 20, 240, 240])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "tp = torch.randn(10,18,240,240)\n",
    "\n",
    "output_gen = gen.forward(tp)\n",
    "print(output_gen.shape)\n",
    "\n",
    "input_disc = torch.cat((output1,tp),dim=1)\n",
    "print(input_disc.shape)\n",
    "\n",
    "output_disc = disc.forward(input_disc)\n",
    "print(output_disc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "adl_dset = AdlDataset(\"adl_dataset.hdf5\",transform)\n",
    "dataloader = DataLoader(adl_dset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "# Final Model\n",
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "\n",
    "# Sqaured Error Loss and Binary Cross Entropy Loss\n",
    "mse_cri = nn.MSELoss(True)\n",
    "entropy_cri = nn.BCELoss(True)\n",
    "\n",
    "# Optimizer for Squared Error Loss\n",
    "opti = torch.optim.Adam( [gen.parameters(), disc.parameters()] )\n",
    "\n",
    "# [4, 20, 240, 240]\n",
    "\n",
    "# Batch Size\n",
    "batch_size = 16\n",
    "\n",
    "chance = 0\n",
    "for epoch in range(10):\n",
    "\n",
    "    \n",
    "    for index,data in enumerate(dataloader) :\n",
    "    \n",
    "        if (index % 100) == 0 :\n",
    "            print(\"Index : {}\".format(index))\n",
    "    \n",
    "        # generator\n",
    "        if chance == 0 :\n",
    "\n",
    "            # Previous 9 frames\n",
    "            input_ = data[:,0:18,:,:]\n",
    "\n",
    "            # Ground truth of 10th frame for batch_size sets\n",
    "            ground_ = data[:,19:,:,:] \n",
    "\n",
    "            # Important !!\n",
    "            opti.zero_grad()\n",
    "\n",
    "            # Prediction for 10th frame for batch_size sets \n",
    "            pred_ = gen.forward(input_)\n",
    "\n",
    "            # MSE Loss\n",
    "            loss_mse = mse_cri(pred_,ground_)\n",
    "\n",
    "            # Input to the discriminator\n",
    "            disc_input = torch.cat((input_,pred_), dim = 1)\n",
    "\n",
    "            # Prediction by discriminator\n",
    "            pred_disc = disc.forward(disc_input)\n",
    "\n",
    "            # Cross Entropy Loss\n",
    "            loss_entropy = entropy_cri(pred_dic, np.zeros(shape = (batch_size,1)))\n",
    "\n",
    "            # Accumalate gradients\n",
    "            loss_mse.backward()\n",
    "            loss_entropy.backward()\n",
    "\n",
    "            # Perform backprop\n",
    "            opti.step()\n",
    "\n",
    "            chance = 1\n",
    "\n",
    "        else :\n",
    "\n",
    "            # Important !!\n",
    "            opti.zero_grad()\n",
    "            \n",
    "            # Prediction by discriminator\n",
    "            pred_disc = disc.forward(data)\n",
    "            \n",
    "            # Cross Entropy Loss\n",
    "            loss_entropy = entropy_cri(pred_dic, np.ones(shape = (batch_size,1)))\n",
    "            \n",
    "            # Accumalate gradients\n",
    "            loss_entropy.backward()\n",
    "            \n",
    "            # Perform backprop\n",
    "            opti.step()\n",
    "            \n",
    "            chance = 0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
