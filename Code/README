There are four important files in this folder

A) adl_dataset_create.ipynb
B) adl_dataset_test.ipynb
C) flow_gans.ipynb
D) Model U-Net for Optical Flow Estimation.ipynb

A) adl_dataset_create.ipynb
This script creates an efficient ".hdf5" file named "adl_dataset". This combines the preprocessed frames in the train_data folder which have been passed through PwC Net.

B) adl_dataset_test.ipynb
This script creates an efficient ".hdf5" file named "adl_dataset". This combines the preprocessed frames in the test_data folder which have been passed through PwC Net.

C) Model U-Net for Optical Flow Estimation.ipynb
A temporary file that includes the architectures of the generator and the discriminator.

D) flow_gans.ipynb
This script contains the training code for GANs and also predicts and saves some optical flow frames from the training_data.


Step 1: Create a new conda environment using the environment.yml file

Step 2: All files can be run by "jupyter notebook <filename.ipynb>"

	A) First Run "jupyter notebook adl_dataset_create.ipynb" in the terminal
	B) Second Run "jupyter notebook adl_dataset_test.ipynb" in the terminal
	C) Finally Run "jupyter notebook flow_gans.ipynb"
	
	
Please Note the ".npy" files in the train_data and test_data folder have been created by the script "pwcnet_predict_from_img_pairs.ipynb" located in the tfoptflow.
"pwcnet_predict_from_img_pairs.ipynb" is the only file we created, all other files have been provided by Nvidia.
